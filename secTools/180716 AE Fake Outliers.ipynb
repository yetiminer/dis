{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(35)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(35)\n",
    "\n",
    "import keras\n",
    "from ae_designs_depth import model_7h, model_5h, model_3h\n",
    "from secTools import yamlLoad\n",
    "from general_loader import ds_from_db\n",
    "from data_manipulation import remove_outlier,augment_x\n",
    "import numpy as np\n",
    "from secTools import yamlLoad\n",
    "from sklearn.model_selection import train_test_split\n",
    "from custom_loss import ( make_recon_loss_combi,sparse_recon_loss_abs,\n",
    "                         make_sparse_recon_loss_combi,sparse_recon_loss_mse, np_sparse_loss)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.optimizers import Adam\n",
    "from Autoencoders import (autoencoder, plot_loss_dic,save_ae_dic,create_eval_dic,\n",
    "                          load_ae_weights,load_ae_dic,create_loss_param_table,\n",
    "                         model_loss_wrap,fit_model_dic)\n",
    "from AE_Designs import  model_eighth\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.models import load_model, model_from_json\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import yaml\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_dic={'pickle_file':'ds180704'}\n",
    "ds=ds_from_db(**ds_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records dropped where no normaliser: 326\n",
      "Number of records dropped where no normaliser: 119\n"
     ]
    }
   ],
   "source": [
    "ds.normalise(['pAssets','pLiabilitiesAndStockholdersEquity'],reorder=True,inplace=True)\n",
    "ds.normalise(['pAssets','pLiabilitiesAndStockholdersEquity'],reorder=True,inplace=True)\n",
    "\n",
    "#I can't figure out why I need to do this twice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>Assets</th>\n",
       "      <th>pAssets</th>\n",
       "      <th>pCashAndCashEquivalentsAtCarryingValue</th>\n",
       "      <th>CashAndCashEquivalentsAtCarryingValue</th>\n",
       "      <th>LiabilitiesAndStockholdersEquity</th>\n",
       "      <th>pLiabilitiesAndStockholdersEquity</th>\n",
       "      <th>NetIncomeLoss</th>\n",
       "      <th>pNetIncomeLoss</th>\n",
       "      <th>pStockholdersEquity</th>\n",
       "      <th>StockholdersEquity</th>\n",
       "      <th>...</th>\n",
       "      <th>IncreaseDecreaseInOtherNoncurrentLiabilities</th>\n",
       "      <th>pIncreaseDecreaseInOtherNoncurrentLiabilities</th>\n",
       "      <th>pCapitalLeaseObligationsIncurred</th>\n",
       "      <th>pStockRepurchasedDuringPeriodValue</th>\n",
       "      <th>CapitalLeaseObligationsIncurred</th>\n",
       "      <th>StockRepurchasedDuringPeriodValue</th>\n",
       "      <th>OtherSalesRevenueNet</th>\n",
       "      <th>pOtherSalesRevenueNet</th>\n",
       "      <th>ValuationAllowancesAndReservesBalance</th>\n",
       "      <th>pValuationAllowancesAndReservesBalance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adsh</th>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Assets, pAssets, pCashAndCashEquivalentsAtCarryingValue, CashAndCashEquivalentsAtCarryingValue, LiabilitiesAndStockholdersEquity, pLiabilitiesAndStockholdersEquity, NetIncomeLoss, pNetIncomeLoss, pStockholdersEquity, StockholdersEquity, AssetsCurrent, pAssetsCurrent, LiabilitiesCurrent, pLiabilitiesCurrent, OperatingIncomeLoss, pOperatingIncomeLoss, pCashAndCashEquivalentsPeriodIncreaseDecrease, CashAndCashEquivalentsPeriodIncreaseDecrease, RetainedEarningsAccumulatedDeficit, pRetainedEarningsAccumulatedDeficit, PropertyPlantAndEquipmentNet, pPropertyPlantAndEquipmentNet, CommonStockValue, pCommonStockValue, pNetCashProvidedByUsedInOperatingActivities, NetCashProvidedByUsedInOperatingActivities, IncomeTaxExpenseBenefit, pIncomeTaxExpenseBenefit, pNetCashProvidedByUsedInFinancingActivities, NetCashProvidedByUsedInFinancingActivities, ShareBasedCompensation, pShareBasedCompensation, pNetCashProvidedByUsedInInvestingActivities, NetCashProvidedByUsedInInvestingActivities, pPaymentsToAcquirePropertyPlantAndEquipment, PaymentsToAcquirePropertyPlantAndEquipment, AccountsPayableCurrent, pAccountsPayableCurrent, Liabilities, pLiabilities, AccumulatedDepreciationDepletionAndAmortizationPropertyPlantAndEquipment, InterestExpense, pAccumulatedDepreciationDepletionAndAmortizationPropertyPlantAndEquipment, pInterestExpense, IncreaseDecreaseInAccountsReceivable, pIncreaseDecreaseInAccountsReceivable, DeferredIncomeTaxExpenseBenefit, pDeferredIncomeTaxExpenseBenefit, AccountsReceivableNetCurrent, pAccountsReceivableNetCurrent, PropertyPlantAndEquipmentGross, pPropertyPlantAndEquipmentGross, IncreaseDecreaseInInventories, pIncreaseDecreaseInInventories, OtherAssetsNoncurrent, pOtherAssetsNoncurrent, ComprehensiveIncomeNetOfTax, pComprehensiveIncomeNetOfTax, AccumulatedOtherComprehensiveIncomeLossNetOfTax, pAccumulatedOtherComprehensiveIncomeLossNetOfTax, InterestPaid, pInterestPaid, DepreciationDepletionAndAmortization, pDepreciationDepletionAndAmortization, Depreciation, pDepreciation, GrossProfit, pGrossProfit, DeferredTaxAssetsValuationAllowance, OperatingExpenses, pDeferredTaxAssetsValuationAllowance, pOperatingExpenses, InventoryNet, pInventoryNet, Goodwill, pGoodwill, IncreaseDecreaseInAccountsPayable, pIncreaseDecreaseInAccountsPayable, IncomeLossFromContinuingOperationsBeforeIncomeTaxesMinorityInterestAndIncomeLossFromEquityMethodInvestments, pIncomeLossFromContinuingOperationsBeforeIncomeTaxesMinorityInterestAndIncomeLossFromEquityMethodInvestments, GeneralAndAdministrativeExpense, pGeneralAndAdministrativeExpense, CurrentStateAndLocalTaxExpenseBenefit, pCurrentStateAndLocalTaxExpenseBenefit, AdditionalPaidInCapital, CurrentFederalTaxExpenseBenefit, pCurrentFederalTaxExpenseBenefit, pAdditionalPaidInCapital, CurrentIncomeTaxExpenseBenefit, pCurrentIncomeTaxExpenseBenefit, AccruedLiabilitiesCurrent, pAccruedLiabilitiesCurrent, DeferredFederalIncomeTaxExpenseBenefit, pDeferredFederalIncomeTaxExpenseBenefit, OtherNonoperatingIncomeExpense, pOtherNonoperatingIncomeExpense, SellingGeneralAndAdministrativeExpense, pSellingGeneralAndAdministrativeExpense, OtherLiabilitiesNoncurrent, IncreaseDecreaseInPrepaidDeferredExpenseAndOtherAssets, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 520 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checker(df2):\n",
    "    return df2[(df2.pAssets!=1)&(df2.pLiabilitiesAndStockholdersEquity!=1)]\n",
    "#checker(ds.FT.dropna())\n",
    "checker(ds.FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anywayed/Documents/dis/secTools/data_manipulation.py:29: RuntimeWarning: invalid value encountered in greater\n",
      "  X[np.abs(X)>level_x]=np.nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=ds.FT.values\n",
    "Y=ds.FT.index.values\n",
    "X=remove_outlier(X,2.5,replace_nan=True)\n",
    "\n",
    "assert(~np.any(np.isnan(X)))\n",
    "\n",
    "X=X[:,0:200]\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=35)\n",
    "\n",
    "\n",
    "recon_loss_combi=make_recon_loss_combi(0.5)\n",
    "sparse_recon_loss_combi=make_sparse_recon_loss_combi(0.5)\n",
    "loss=sparse_recon_loss_combi\n",
    "\n",
    "metrics=[recon_loss_combi,sparse_recon_loss_combi,sparse_recon_loss_mse,sparse_recon_loss_abs]\n",
    "\n",
    "test_data=[x_test,x_test]\n",
    "train_data=[x_train,x_train]\n",
    "\n",
    "#early stop setting below is default but explicitly stated here\n",
    "ES=EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "ker_init=glorot_normal(seed=22)\n",
    "opt=Adam(lr=0.001)\n",
    "\n",
    "train_dic={'train_data':train_data,'test_data':test_data,'loss':loss,\n",
    "           'compile':True,'epochs':100,'batch_size':124,'optimizer':opt,\n",
    "          'early_stop':ES,'metrics':metrics}\n",
    "nodes=[32,16,32]\n",
    "layer_dic={'drop_ra':0.0,'l1_reg':0, 'g_noise':0.05, 'ker_init':ker_init,'nodes':nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21161 samples, validate on 7054 samples\n",
      "Epoch 1/100\n",
      "21161/21161 [==============================] - 1s 66us/step - loss: 0.1322 - recon_loss_combi: 0.0573 - sparse_recon_loss_combi: 0.1322 - sparse_recon_loss_mse: 0.1014 - sparse_recon_loss_abs: 0.1631 - val_loss: 0.0873 - val_recon_loss_combi: 0.0382 - val_sparse_recon_loss_combi: 0.0873 - val_sparse_recon_loss_mse: 0.0578 - val_sparse_recon_loss_abs: 0.1169\n",
      "Epoch 2/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0788 - recon_loss_combi: 0.0342 - sparse_recon_loss_combi: 0.0788 - sparse_recon_loss_mse: 0.0515 - sparse_recon_loss_abs: 0.1062 - val_loss: 0.0696 - val_recon_loss_combi: 0.0305 - val_sparse_recon_loss_combi: 0.0696 - val_sparse_recon_loss_mse: 0.0433 - val_sparse_recon_loss_abs: 0.0960\n",
      "Epoch 3/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0674 - recon_loss_combi: 0.0292 - sparse_recon_loss_combi: 0.0674 - sparse_recon_loss_mse: 0.0419 - sparse_recon_loss_abs: 0.0929 - val_loss: 0.0616 - val_recon_loss_combi: 0.0269 - val_sparse_recon_loss_combi: 0.0616 - val_sparse_recon_loss_mse: 0.0372 - val_sparse_recon_loss_abs: 0.0860\n",
      "Epoch 4/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0618 - recon_loss_combi: 0.0268 - sparse_recon_loss_combi: 0.0618 - sparse_recon_loss_mse: 0.0373 - sparse_recon_loss_abs: 0.0863 - val_loss: 0.0573 - val_recon_loss_combi: 0.0251 - val_sparse_recon_loss_combi: 0.0573 - val_sparse_recon_loss_mse: 0.0337 - val_sparse_recon_loss_abs: 0.0809\n",
      "Epoch 5/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0587 - recon_loss_combi: 0.0254 - sparse_recon_loss_combi: 0.0587 - sparse_recon_loss_mse: 0.0349 - sparse_recon_loss_abs: 0.0826 - val_loss: 0.0547 - val_recon_loss_combi: 0.0239 - val_sparse_recon_loss_combi: 0.0547 - val_sparse_recon_loss_mse: 0.0320 - val_sparse_recon_loss_abs: 0.0775\n",
      "Epoch 6/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0564 - recon_loss_combi: 0.0244 - sparse_recon_loss_combi: 0.0564 - sparse_recon_loss_mse: 0.0331 - sparse_recon_loss_abs: 0.0797 - val_loss: 0.0522 - val_recon_loss_combi: 0.0228 - val_sparse_recon_loss_combi: 0.0522 - val_sparse_recon_loss_mse: 0.0301 - val_sparse_recon_loss_abs: 0.0744\n",
      "Epoch 7/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0545 - recon_loss_combi: 0.0236 - sparse_recon_loss_combi: 0.0545 - sparse_recon_loss_mse: 0.0316 - sparse_recon_loss_abs: 0.0774 - val_loss: 0.0507 - val_recon_loss_combi: 0.0222 - val_sparse_recon_loss_combi: 0.0507 - val_sparse_recon_loss_mse: 0.0289 - val_sparse_recon_loss_abs: 0.0725\n",
      "Epoch 8/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0529 - recon_loss_combi: 0.0230 - sparse_recon_loss_combi: 0.0529 - sparse_recon_loss_mse: 0.0303 - sparse_recon_loss_abs: 0.0756 - val_loss: 0.0491 - val_recon_loss_combi: 0.0215 - val_sparse_recon_loss_combi: 0.0491 - val_sparse_recon_loss_mse: 0.0279 - val_sparse_recon_loss_abs: 0.0703\n",
      "Epoch 9/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0518 - recon_loss_combi: 0.0224 - sparse_recon_loss_combi: 0.0518 - sparse_recon_loss_mse: 0.0294 - sparse_recon_loss_abs: 0.0741 - val_loss: 0.0477 - val_recon_loss_combi: 0.0208 - val_sparse_recon_loss_combi: 0.0477 - val_sparse_recon_loss_mse: 0.0267 - val_sparse_recon_loss_abs: 0.0686\n",
      "Epoch 10/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0505 - recon_loss_combi: 0.0219 - sparse_recon_loss_combi: 0.0505 - sparse_recon_loss_mse: 0.0284 - sparse_recon_loss_abs: 0.0725 - val_loss: 0.0467 - val_recon_loss_combi: 0.0204 - val_sparse_recon_loss_combi: 0.0467 - val_sparse_recon_loss_mse: 0.0260 - val_sparse_recon_loss_abs: 0.0674\n",
      "Epoch 11/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0496 - recon_loss_combi: 0.0215 - sparse_recon_loss_combi: 0.0496 - sparse_recon_loss_mse: 0.0278 - sparse_recon_loss_abs: 0.0715 - val_loss: 0.0460 - val_recon_loss_combi: 0.0201 - val_sparse_recon_loss_combi: 0.0460 - val_sparse_recon_loss_mse: 0.0254 - val_sparse_recon_loss_abs: 0.0666\n",
      "Epoch 12/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0486 - recon_loss_combi: 0.0211 - sparse_recon_loss_combi: 0.0486 - sparse_recon_loss_mse: 0.0270 - sparse_recon_loss_abs: 0.0703 - val_loss: 0.0450 - val_recon_loss_combi: 0.0197 - val_sparse_recon_loss_combi: 0.0450 - val_sparse_recon_loss_mse: 0.0247 - val_sparse_recon_loss_abs: 0.0653\n",
      "Epoch 13/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0480 - recon_loss_combi: 0.0208 - sparse_recon_loss_combi: 0.0480 - sparse_recon_loss_mse: 0.0265 - sparse_recon_loss_abs: 0.0694 - val_loss: 0.0445 - val_recon_loss_combi: 0.0195 - val_sparse_recon_loss_combi: 0.0445 - val_sparse_recon_loss_mse: 0.0242 - val_sparse_recon_loss_abs: 0.0647\n",
      "Epoch 14/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0471 - recon_loss_combi: 0.0204 - sparse_recon_loss_combi: 0.0471 - sparse_recon_loss_mse: 0.0259 - sparse_recon_loss_abs: 0.0683 - val_loss: 0.0437 - val_recon_loss_combi: 0.0191 - val_sparse_recon_loss_combi: 0.0437 - val_sparse_recon_loss_mse: 0.0236 - val_sparse_recon_loss_abs: 0.0638\n",
      "Epoch 15/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0465 - recon_loss_combi: 0.0202 - sparse_recon_loss_combi: 0.0465 - sparse_recon_loss_mse: 0.0254 - sparse_recon_loss_abs: 0.0676 - val_loss: 0.0430 - val_recon_loss_combi: 0.0188 - val_sparse_recon_loss_combi: 0.0430 - val_sparse_recon_loss_mse: 0.0232 - val_sparse_recon_loss_abs: 0.0628\n",
      "Epoch 16/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0461 - recon_loss_combi: 0.0200 - sparse_recon_loss_combi: 0.0461 - sparse_recon_loss_mse: 0.0251 - sparse_recon_loss_abs: 0.0671 - val_loss: 0.0424 - val_recon_loss_combi: 0.0186 - val_sparse_recon_loss_combi: 0.0424 - val_sparse_recon_loss_mse: 0.0229 - val_sparse_recon_loss_abs: 0.0619\n",
      "Epoch 17/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0458 - recon_loss_combi: 0.0198 - sparse_recon_loss_combi: 0.0458 - sparse_recon_loss_mse: 0.0249 - sparse_recon_loss_abs: 0.0667 - val_loss: 0.0420 - val_recon_loss_combi: 0.0184 - val_sparse_recon_loss_combi: 0.0420 - val_sparse_recon_loss_mse: 0.0226 - val_sparse_recon_loss_abs: 0.0615\n",
      "Epoch 18/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0453 - recon_loss_combi: 0.0196 - sparse_recon_loss_combi: 0.0453 - sparse_recon_loss_mse: 0.0245 - sparse_recon_loss_abs: 0.0660 - val_loss: 0.0418 - val_recon_loss_combi: 0.0183 - val_sparse_recon_loss_combi: 0.0418 - val_sparse_recon_loss_mse: 0.0223 - val_sparse_recon_loss_abs: 0.0612\n",
      "Epoch 19/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0447 - recon_loss_combi: 0.0194 - sparse_recon_loss_combi: 0.0447 - sparse_recon_loss_mse: 0.0241 - sparse_recon_loss_abs: 0.0653 - val_loss: 0.0411 - val_recon_loss_combi: 0.0180 - val_sparse_recon_loss_combi: 0.0411 - val_sparse_recon_loss_mse: 0.0220 - val_sparse_recon_loss_abs: 0.0603\n",
      "Epoch 20/100\n",
      "21161/21161 [==============================] - 1s 34us/step - loss: 0.0444 - recon_loss_combi: 0.0193 - sparse_recon_loss_combi: 0.0444 - sparse_recon_loss_mse: 0.0239 - sparse_recon_loss_abs: 0.0650 - val_loss: 0.0405 - val_recon_loss_combi: 0.0177 - val_sparse_recon_loss_combi: 0.0405 - val_sparse_recon_loss_mse: 0.0217 - val_sparse_recon_loss_abs: 0.0593\n",
      "Epoch 21/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0442 - recon_loss_combi: 0.0192 - sparse_recon_loss_combi: 0.0442 - sparse_recon_loss_mse: 0.0238 - sparse_recon_loss_abs: 0.0647 - val_loss: 0.0402 - val_recon_loss_combi: 0.0176 - val_sparse_recon_loss_combi: 0.0402 - val_sparse_recon_loss_mse: 0.0216 - val_sparse_recon_loss_abs: 0.0588\n",
      "Epoch 22/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0437 - recon_loss_combi: 0.0189 - sparse_recon_loss_combi: 0.0437 - sparse_recon_loss_mse: 0.0234 - sparse_recon_loss_abs: 0.0639 - val_loss: 0.0399 - val_recon_loss_combi: 0.0174 - val_sparse_recon_loss_combi: 0.0399 - val_sparse_recon_loss_mse: 0.0214 - val_sparse_recon_loss_abs: 0.0584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0435 - recon_loss_combi: 0.0188 - sparse_recon_loss_combi: 0.0435 - sparse_recon_loss_mse: 0.0233 - sparse_recon_loss_abs: 0.0636 - val_loss: 0.0401 - val_recon_loss_combi: 0.0175 - val_sparse_recon_loss_combi: 0.0401 - val_sparse_recon_loss_mse: 0.0214 - val_sparse_recon_loss_abs: 0.0587\n",
      "Epoch 24/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0434 - recon_loss_combi: 0.0188 - sparse_recon_loss_combi: 0.0434 - sparse_recon_loss_mse: 0.0233 - sparse_recon_loss_abs: 0.0635 - val_loss: 0.0399 - val_recon_loss_combi: 0.0174 - val_sparse_recon_loss_combi: 0.0399 - val_sparse_recon_loss_mse: 0.0212 - val_sparse_recon_loss_abs: 0.0585\n",
      "Epoch 25/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0431 - recon_loss_combi: 0.0187 - sparse_recon_loss_combi: 0.0431 - sparse_recon_loss_mse: 0.0230 - sparse_recon_loss_abs: 0.0631 - val_loss: 0.0395 - val_recon_loss_combi: 0.0173 - val_sparse_recon_loss_combi: 0.0395 - val_sparse_recon_loss_mse: 0.0210 - val_sparse_recon_loss_abs: 0.0580\n",
      "Epoch 26/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0429 - recon_loss_combi: 0.0186 - sparse_recon_loss_combi: 0.0429 - sparse_recon_loss_mse: 0.0229 - sparse_recon_loss_abs: 0.0630 - val_loss: 0.0391 - val_recon_loss_combi: 0.0171 - val_sparse_recon_loss_combi: 0.0391 - val_sparse_recon_loss_mse: 0.0209 - val_sparse_recon_loss_abs: 0.0573\n",
      "Epoch 27/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0427 - recon_loss_combi: 0.0185 - sparse_recon_loss_combi: 0.0427 - sparse_recon_loss_mse: 0.0229 - sparse_recon_loss_abs: 0.0626 - val_loss: 0.0387 - val_recon_loss_combi: 0.0169 - val_sparse_recon_loss_combi: 0.0387 - val_sparse_recon_loss_mse: 0.0208 - val_sparse_recon_loss_abs: 0.0566\n",
      "Epoch 28/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0426 - recon_loss_combi: 0.0185 - sparse_recon_loss_combi: 0.0426 - sparse_recon_loss_mse: 0.0228 - sparse_recon_loss_abs: 0.0624 - val_loss: 0.0388 - val_recon_loss_combi: 0.0169 - val_sparse_recon_loss_combi: 0.0388 - val_sparse_recon_loss_mse: 0.0208 - val_sparse_recon_loss_abs: 0.0567\n",
      "Epoch 29/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0426 - recon_loss_combi: 0.0185 - sparse_recon_loss_combi: 0.0426 - sparse_recon_loss_mse: 0.0227 - sparse_recon_loss_abs: 0.0624 - val_loss: 0.0387 - val_recon_loss_combi: 0.0169 - val_sparse_recon_loss_combi: 0.0387 - val_sparse_recon_loss_mse: 0.0208 - val_sparse_recon_loss_abs: 0.0566\n",
      "Epoch 30/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0425 - recon_loss_combi: 0.0184 - sparse_recon_loss_combi: 0.0425 - sparse_recon_loss_mse: 0.0227 - sparse_recon_loss_abs: 0.0623 - val_loss: 0.0387 - val_recon_loss_combi: 0.0169 - val_sparse_recon_loss_combi: 0.0387 - val_sparse_recon_loss_mse: 0.0208 - val_sparse_recon_loss_abs: 0.0566\n",
      "Epoch 31/100\n",
      "21161/21161 [==============================] - 1s 35us/step - loss: 0.0424 - recon_loss_combi: 0.0184 - sparse_recon_loss_combi: 0.0424 - sparse_recon_loss_mse: 0.0226 - sparse_recon_loss_abs: 0.0621 - val_loss: 0.0386 - val_recon_loss_combi: 0.0169 - val_sparse_recon_loss_combi: 0.0386 - val_sparse_recon_loss_mse: 0.0207 - val_sparse_recon_loss_abs: 0.0565\n",
      "Epoch 32/100\n",
      "21161/21161 [==============================] - 1s 35us/step - loss: 0.0422 - recon_loss_combi: 0.0183 - sparse_recon_loss_combi: 0.0422 - sparse_recon_loss_mse: 0.0225 - sparse_recon_loss_abs: 0.0619 - val_loss: 0.0385 - val_recon_loss_combi: 0.0168 - val_sparse_recon_loss_combi: 0.0385 - val_sparse_recon_loss_mse: 0.0205 - val_sparse_recon_loss_abs: 0.0564\n",
      "Epoch 33/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0419 - recon_loss_combi: 0.0181 - sparse_recon_loss_combi: 0.0419 - sparse_recon_loss_mse: 0.0223 - sparse_recon_loss_abs: 0.0614 - val_loss: 0.0385 - val_recon_loss_combi: 0.0168 - val_sparse_recon_loss_combi: 0.0385 - val_sparse_recon_loss_mse: 0.0205 - val_sparse_recon_loss_abs: 0.0566\n",
      "Epoch 34/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0418 - recon_loss_combi: 0.0181 - sparse_recon_loss_combi: 0.0418 - sparse_recon_loss_mse: 0.0222 - sparse_recon_loss_abs: 0.0613 - val_loss: 0.0380 - val_recon_loss_combi: 0.0166 - val_sparse_recon_loss_combi: 0.0380 - val_sparse_recon_loss_mse: 0.0204 - val_sparse_recon_loss_abs: 0.0556\n",
      "Epoch 35/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0417 - recon_loss_combi: 0.0181 - sparse_recon_loss_combi: 0.0417 - sparse_recon_loss_mse: 0.0222 - sparse_recon_loss_abs: 0.0612 - val_loss: 0.0378 - val_recon_loss_combi: 0.0165 - val_sparse_recon_loss_combi: 0.0378 - val_sparse_recon_loss_mse: 0.0203 - val_sparse_recon_loss_abs: 0.0554\n",
      "Epoch 36/100\n",
      "21161/21161 [==============================] - 1s 34us/step - loss: 0.0418 - recon_loss_combi: 0.0181 - sparse_recon_loss_combi: 0.0418 - sparse_recon_loss_mse: 0.0222 - sparse_recon_loss_abs: 0.0613 - val_loss: 0.0379 - val_recon_loss_combi: 0.0166 - val_sparse_recon_loss_combi: 0.0379 - val_sparse_recon_loss_mse: 0.0203 - val_sparse_recon_loss_abs: 0.0555\n",
      "Epoch 37/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0416 - recon_loss_combi: 0.0180 - sparse_recon_loss_combi: 0.0416 - sparse_recon_loss_mse: 0.0222 - sparse_recon_loss_abs: 0.0611 - val_loss: 0.0379 - val_recon_loss_combi: 0.0166 - val_sparse_recon_loss_combi: 0.0379 - val_sparse_recon_loss_mse: 0.0202 - val_sparse_recon_loss_abs: 0.0556\n",
      "Epoch 38/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0417 - recon_loss_combi: 0.0181 - sparse_recon_loss_combi: 0.0417 - sparse_recon_loss_mse: 0.0222 - sparse_recon_loss_abs: 0.0612 - val_loss: 0.0378 - val_recon_loss_combi: 0.0165 - val_sparse_recon_loss_combi: 0.0378 - val_sparse_recon_loss_mse: 0.0202 - val_sparse_recon_loss_abs: 0.0555\n",
      "Epoch 39/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0414 - recon_loss_combi: 0.0179 - sparse_recon_loss_combi: 0.0414 - sparse_recon_loss_mse: 0.0221 - sparse_recon_loss_abs: 0.0607 - val_loss: 0.0373 - val_recon_loss_combi: 0.0163 - val_sparse_recon_loss_combi: 0.0373 - val_sparse_recon_loss_mse: 0.0200 - val_sparse_recon_loss_abs: 0.0547\n",
      "Epoch 40/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0413 - recon_loss_combi: 0.0179 - sparse_recon_loss_combi: 0.0413 - sparse_recon_loss_mse: 0.0219 - sparse_recon_loss_abs: 0.0607 - val_loss: 0.0375 - val_recon_loss_combi: 0.0164 - val_sparse_recon_loss_combi: 0.0375 - val_sparse_recon_loss_mse: 0.0200 - val_sparse_recon_loss_abs: 0.0549\n",
      "Epoch 41/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0411 - recon_loss_combi: 0.0178 - sparse_recon_loss_combi: 0.0411 - sparse_recon_loss_mse: 0.0218 - sparse_recon_loss_abs: 0.0604 - val_loss: 0.0375 - val_recon_loss_combi: 0.0164 - val_sparse_recon_loss_combi: 0.0375 - val_sparse_recon_loss_mse: 0.0200 - val_sparse_recon_loss_abs: 0.0549\n",
      "Epoch 42/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0411 - recon_loss_combi: 0.0178 - sparse_recon_loss_combi: 0.0411 - sparse_recon_loss_mse: 0.0218 - sparse_recon_loss_abs: 0.0603 - val_loss: 0.0372 - val_recon_loss_combi: 0.0163 - val_sparse_recon_loss_combi: 0.0372 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0545\n",
      "Epoch 43/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0411 - recon_loss_combi: 0.0178 - sparse_recon_loss_combi: 0.0411 - sparse_recon_loss_mse: 0.0218 - sparse_recon_loss_abs: 0.0603 - val_loss: 0.0372 - val_recon_loss_combi: 0.0163 - val_sparse_recon_loss_combi: 0.0372 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0545\n",
      "Epoch 44/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0409 - recon_loss_combi: 0.0177 - sparse_recon_loss_combi: 0.0409 - sparse_recon_loss_mse: 0.0217 - sparse_recon_loss_abs: 0.0601 - val_loss: 0.0371 - val_recon_loss_combi: 0.0162 - val_sparse_recon_loss_combi: 0.0371 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0410 - recon_loss_combi: 0.0178 - sparse_recon_loss_combi: 0.0410 - sparse_recon_loss_mse: 0.0217 - sparse_recon_loss_abs: 0.0602 - val_loss: 0.0371 - val_recon_loss_combi: 0.0162 - val_sparse_recon_loss_combi: 0.0371 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0543\n",
      "Epoch 46/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0407 - recon_loss_combi: 0.0177 - sparse_recon_loss_combi: 0.0407 - sparse_recon_loss_mse: 0.0216 - sparse_recon_loss_abs: 0.0599 - val_loss: 0.0372 - val_recon_loss_combi: 0.0163 - val_sparse_recon_loss_combi: 0.0372 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0545\n",
      "Epoch 47/100\n",
      "21161/21161 [==============================] - 1s 33us/step - loss: 0.0409 - recon_loss_combi: 0.0177 - sparse_recon_loss_combi: 0.0409 - sparse_recon_loss_mse: 0.0217 - sparse_recon_loss_abs: 0.0601 - val_loss: 0.0369 - val_recon_loss_combi: 0.0161 - val_sparse_recon_loss_combi: 0.0369 - val_sparse_recon_loss_mse: 0.0199 - val_sparse_recon_loss_abs: 0.0540\n",
      "Epoch 48/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0408 - recon_loss_combi: 0.0177 - sparse_recon_loss_combi: 0.0408 - sparse_recon_loss_mse: 0.0217 - sparse_recon_loss_abs: 0.0599 - val_loss: 0.0368 - val_recon_loss_combi: 0.0161 - val_sparse_recon_loss_combi: 0.0368 - val_sparse_recon_loss_mse: 0.0198 - val_sparse_recon_loss_abs: 0.0538\n",
      "Epoch 49/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0407 - recon_loss_combi: 0.0176 - sparse_recon_loss_combi: 0.0407 - sparse_recon_loss_mse: 0.0216 - sparse_recon_loss_abs: 0.0598 - val_loss: 0.0369 - val_recon_loss_combi: 0.0161 - val_sparse_recon_loss_combi: 0.0369 - val_sparse_recon_loss_mse: 0.0198 - val_sparse_recon_loss_abs: 0.0540\n",
      "Epoch 50/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0405 - recon_loss_combi: 0.0176 - sparse_recon_loss_combi: 0.0405 - sparse_recon_loss_mse: 0.0215 - sparse_recon_loss_abs: 0.0595 - val_loss: 0.0367 - val_recon_loss_combi: 0.0160 - val_sparse_recon_loss_combi: 0.0367 - val_sparse_recon_loss_mse: 0.0197 - val_sparse_recon_loss_abs: 0.0536\n",
      "Epoch 51/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0406 - recon_loss_combi: 0.0176 - sparse_recon_loss_combi: 0.0406 - sparse_recon_loss_mse: 0.0215 - sparse_recon_loss_abs: 0.0596 - val_loss: 0.0369 - val_recon_loss_combi: 0.0161 - val_sparse_recon_loss_combi: 0.0369 - val_sparse_recon_loss_mse: 0.0198 - val_sparse_recon_loss_abs: 0.0539\n",
      "Epoch 52/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0403 - recon_loss_combi: 0.0175 - sparse_recon_loss_combi: 0.0403 - sparse_recon_loss_mse: 0.0214 - sparse_recon_loss_abs: 0.0592 - val_loss: 0.0365 - val_recon_loss_combi: 0.0159 - val_sparse_recon_loss_combi: 0.0365 - val_sparse_recon_loss_mse: 0.0197 - val_sparse_recon_loss_abs: 0.0533\n",
      "Epoch 53/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0403 - recon_loss_combi: 0.0175 - sparse_recon_loss_combi: 0.0403 - sparse_recon_loss_mse: 0.0215 - sparse_recon_loss_abs: 0.0592 - val_loss: 0.0365 - val_recon_loss_combi: 0.0160 - val_sparse_recon_loss_combi: 0.0365 - val_sparse_recon_loss_mse: 0.0197 - val_sparse_recon_loss_abs: 0.0534\n",
      "Epoch 54/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0404 - recon_loss_combi: 0.0175 - sparse_recon_loss_combi: 0.0404 - sparse_recon_loss_mse: 0.0214 - sparse_recon_loss_abs: 0.0594 - val_loss: 0.0366 - val_recon_loss_combi: 0.0160 - val_sparse_recon_loss_combi: 0.0366 - val_sparse_recon_loss_mse: 0.0197 - val_sparse_recon_loss_abs: 0.0534\n",
      "Epoch 55/100\n",
      "21161/21161 [==============================] - 1s 31us/step - loss: 0.0402 - recon_loss_combi: 0.0174 - sparse_recon_loss_combi: 0.0402 - sparse_recon_loss_mse: 0.0214 - sparse_recon_loss_abs: 0.0590 - val_loss: 0.0367 - val_recon_loss_combi: 0.0161 - val_sparse_recon_loss_combi: 0.0367 - val_sparse_recon_loss_mse: 0.0198 - val_sparse_recon_loss_abs: 0.0537\n",
      "Epoch 56/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0402 - recon_loss_combi: 0.0174 - sparse_recon_loss_combi: 0.0402 - sparse_recon_loss_mse: 0.0214 - sparse_recon_loss_abs: 0.0591 - val_loss: 0.0363 - val_recon_loss_combi: 0.0159 - val_sparse_recon_loss_combi: 0.0363 - val_sparse_recon_loss_mse: 0.0196 - val_sparse_recon_loss_abs: 0.0530\n",
      "Epoch 57/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0401 - recon_loss_combi: 0.0174 - sparse_recon_loss_combi: 0.0401 - sparse_recon_loss_mse: 0.0213 - sparse_recon_loss_abs: 0.0589 - val_loss: 0.0362 - val_recon_loss_combi: 0.0158 - val_sparse_recon_loss_combi: 0.0362 - val_sparse_recon_loss_mse: 0.0196 - val_sparse_recon_loss_abs: 0.0528\n",
      "Epoch 58/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0400 - recon_loss_combi: 0.0174 - sparse_recon_loss_combi: 0.0400 - sparse_recon_loss_mse: 0.0213 - sparse_recon_loss_abs: 0.0588 - val_loss: 0.0363 - val_recon_loss_combi: 0.0159 - val_sparse_recon_loss_combi: 0.0363 - val_sparse_recon_loss_mse: 0.0196 - val_sparse_recon_loss_abs: 0.0530\n",
      "Epoch 59/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0400 - recon_loss_combi: 0.0173 - sparse_recon_loss_combi: 0.0400 - sparse_recon_loss_mse: 0.0212 - sparse_recon_loss_abs: 0.0588 - val_loss: 0.0363 - val_recon_loss_combi: 0.0159 - val_sparse_recon_loss_combi: 0.0363 - val_sparse_recon_loss_mse: 0.0196 - val_sparse_recon_loss_abs: 0.0530\n",
      "Epoch 60/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0400 - recon_loss_combi: 0.0173 - sparse_recon_loss_combi: 0.0400 - sparse_recon_loss_mse: 0.0213 - sparse_recon_loss_abs: 0.0588 - val_loss: 0.0362 - val_recon_loss_combi: 0.0158 - val_sparse_recon_loss_combi: 0.0362 - val_sparse_recon_loss_mse: 0.0196 - val_sparse_recon_loss_abs: 0.0527\n",
      "Epoch 61/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0400 - recon_loss_combi: 0.0173 - sparse_recon_loss_combi: 0.0400 - sparse_recon_loss_mse: 0.0213 - sparse_recon_loss_abs: 0.0587 - val_loss: 0.0362 - val_recon_loss_combi: 0.0158 - val_sparse_recon_loss_combi: 0.0362 - val_sparse_recon_loss_mse: 0.0195 - val_sparse_recon_loss_abs: 0.0528\n",
      "Epoch 62/100\n",
      "21161/21161 [==============================] - 1s 32us/step - loss: 0.0400 - recon_loss_combi: 0.0173 - sparse_recon_loss_combi: 0.0400 - sparse_recon_loss_mse: 0.0213 - sparse_recon_loss_abs: 0.0587 - val_loss: 0.0363 - val_recon_loss_combi: 0.0159 - val_sparse_recon_loss_combi: 0.0363 - val_sparse_recon_loss_mse: 0.0197 - val_sparse_recon_loss_abs: 0.0530\n",
      "Epoch 00062: early stopping\n"
     ]
    }
   ],
   "source": [
    "nodes=[32,16,32]\n",
    "layers=model_3h(x_train,drop_ra=0.0,l1_reg=0, g_noise=0.05, ker_init=ker_init,nodes=nodes)\n",
    "\n",
    "ae_321632=autoencoder(layers,name='321632',**train_dic)\n",
    "ae_321632.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.036217988, 0.03621798383531186)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fit=ae_321632.model.predict(x_test)\n",
    "x_fit_train=ae_321632.model.predict(x_train)\n",
    "from custom_loss import test_sparse_function\n",
    "test_sparse_function(x_test,x_fit,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7054/7054 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03653826123895137,\n",
       " 0.015878510367529804,\n",
       " 0.03653826123895137,\n",
       " 0.01983553871379329,\n",
       " 0.053240983682252344]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_321632.model.evaluate(x=x_test,y=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=list(map(lambda x: np_sparse_loss(x_fit[x],x_test[x]),range(1,x_fit.shape[0])))\n",
    "losses=np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fake_financial(x_test,y_test,ds,reps,var_scale=1):\n",
    "    #takes\n",
    "    \n",
    "    x_test_des=ds.FT.loc[y_test].describe()\n",
    "    x_test_des.loc['std','pAssets']=0\n",
    "    x_test_des.loc['std','pLiabilitiesAndStockholdersEquity']=0\n",
    "    \n",
    "    #generate a vector of probs that a field is populated\n",
    "    prob_vec=(ds.FT.loc[y_test]>0).sum().values/x_test.shape[0]\n",
    "\n",
    "    #get standard deviation of each field\n",
    "    \n",
    "    x_test_std=x_test_des.loc['std'].values\n",
    "    \n",
    "    def make_rand_alt(p):\n",
    "        #generate a binary sequence length=#features, from this vector prob\n",
    "        alteration_yes_no=np.random.binomial(1,prob_vec)\n",
    "\n",
    "        #random vector with standard deviations according to variables\n",
    "        random_alterations=np.random.normal(scale=var_scale*x_test_std)\n",
    "\n",
    "        out=np.multiply(random_alterations,alteration_yes_no)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    final_out=list(map(make_rand_alt,range(1,reps+1)))\n",
    "\n",
    "    return final_out\n",
    "\n",
    "def make_fake_data(x_test,y_test,ds,num_fakes=7000,method='easy'):\n",
    "    #adds noise to input financials. easy adds noise anywhere according to distribution of fields\n",
    "    #and frequency of field. Hard method only adds noise to fields which are non-zero to begin with \n",
    "    \n",
    "    alts=fake_financial(x_test,y_test,ds,num_fakes,var_scale=1)\n",
    "    if method=='easy':\n",
    "        \n",
    "        x_fake=x_test[0:num_fakes]+np.stack(alts)[:,0:200]\n",
    "        x_fake[np.abs(x_fake>2.5)]=0\n",
    "    elif method=='hard':\n",
    "        \n",
    "        x_fake=x_test[0:num_fakes]\n",
    "        x_fake[x_fake>0]=x_fake[x_fake>0]+np.stack(alts)[:,0:200][x_fake>0]\n",
    "        x_fake[np.abs(x_fake)>2.5]=0\n",
    "    else:\n",
    "        print(\"'method either 'easy' or 'hard'\")\n",
    "        raise AssertionError\n",
    "    \n",
    "    return x_fake\n",
    "\n",
    "\n",
    "def evaluate_loss(x,y):\n",
    "    losses=list(map(lambda x: np_sparse_loss(x_fit[x],x_test[x]),range(1,x_fit.shape[0])))\n",
    "    losses=np.array(losses)\n",
    "    return losses\n",
    "\n",
    "def two_class_hist(losses,fake_losses):\n",
    "\n",
    "    plt.figure()\n",
    "    [n_re,bins,patches]=plt.hist(losses,bins=100,density=True,range=[0,1], alpha=0.7)\n",
    "    [n_fa,bins,patches_f]=plt.hist(fake_losses,bins=bins,density=True,alpha=0.7)\n",
    "    \n",
    "    plt.legend(['Real','Fake'])\n",
    "    plt.title('Distribution of Reconstruction Loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_fake=make_fake_data(x_test,y_test,ds,num_fakes=7000)\n",
    "x_fake_fit=ae_321632.model.predict(x_fake)\n",
    "fake_losses=evaluate_loss(x_fake_fit,x_fake)\n",
    "fig1=two_class_hist(losses,fake_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_fake_h=make_fake_data(x_test,y_test,ds,num_fakes=7000,method='hard')\n",
    "x_fake_h_fit=ae_321632.model.predict(x_fake)\n",
    "fake_losses_h=evaluate_loss(x_fake_h_fit,x_fake_h)\n",
    "fig2=two_class_hist(losses,fake_losses_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def fit_svm(losses,fake_losses):\n",
    "    X=np.append(losses,fake_losses)\n",
    "    Y=np.append(np.zeros(losses.shape),np.ones(fake_losses.shape))\n",
    "    X=X.reshape(-1, 1)\n",
    "\n",
    "    clf=svm.LinearSVC(random_state=35)\n",
    "    clf.fit(X,Y)\n",
    "    type1_errors=sum(clf.predict(losses.reshape(-1,1)))\n",
    "    print(type1_errors)\n",
    "    type2_errors=fake_losses.shape[0]-sum(clf.predict(fake_losses.reshape(-1,1)))\n",
    "    print(type2_errors)\n",
    "    total_error_rate=(type1_errors+type2_errors)/X.shape[0]\n",
    "    type1_error_rate=type1_errors/losses.shape[0]\n",
    "    type2_error_rate=type2_errors/fake_losses.shape[0]\n",
    "    print(fake_losses.shape[0])\n",
    "    return total_error_rate,type1_error_rate,type2_error_rate\n",
    "                                       \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
